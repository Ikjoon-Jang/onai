import faiss
import numpy as np
import pickle
import os
from typing import List, Tuple
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
env_path = os.path.join(os.path.dirname(__file__), "..", ".env")
load_dotenv(dotenv_path=env_path)

# í™˜ê²½ ë³€ìˆ˜ë¡œë¶€í„° ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
INDEX_FILE = os.getenv("FAISS_INDEX_FILE", "faiss_index.index")
META_FILE = os.getenv("FAISS_META_FILE", "faiss_metadata.pkl")
VECTOR_SIZE = 1536  # OpenAI embedding vector size

# ğŸ”¹ ë²¡í„° + ë¬¸ì¥ì„ FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„°ì— ì €ì¥
def save_embeddings_to_faiss(sentences: List[str], embeddings: List[List[float]]):
    vectors = np.array(embeddings, dtype="float32")

    # ê¸°ì¡´ ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
    if os.path.exists(INDEX_FILE):
        index = faiss.read_index(INDEX_FILE)
        with open(META_FILE, "rb") as f:
            metadata = pickle.load(f)
    else:
        index = faiss.IndexFlatL2(VECTOR_SIZE)
        metadata = []

    # ë²¡í„° ì¶”ê°€
    index.add(vectors)
    metadata.extend(sentences)

    # ì €ì¥
    faiss.write_index(index, INDEX_FILE)
    with open(META_FILE, "wb") as f:
        pickle.dump(metadata, f)

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {len(sentences)}ê°œ ë¬¸ì¥ì„ FAISSì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

# ğŸ”¹ FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_index_and_metadata() -> Tuple[faiss.IndexFlatL2, List[str]]:
    index = faiss.read_index(INDEX_FILE)
    with open(META_FILE, "rb") as f:
        metadata = pickle.load(f)
    return index, metadata

# ğŸ”¹ ì§ˆì˜ ë²¡í„°ë¡œ ìœ ì‚¬ ë¬¸ì¥ ê²€ìƒ‰
def search_faiss(query_vector, index, metadata, k=5):
    query = np.array([query_vector], dtype="float32")
    D, I = index.search(query, k)
    return [(metadata[i]["text"], D[0][idx]) for idx, i in enumerate(I[0])]
