import streamlit as st
import time
import os
from dotenv import load_dotenv
from aiqa.rag_query import generate_answer
from embedding.faiss_store import load_index_and_metadata, search_faiss
from embedding.embedding import get_embedding

# ğŸ“¦ .env ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
FAISS_REFRESH_INTERVAL = int(os.getenv("FAISS_REFRESH_INTERVAL", 60))

# ğŸ“ ì´ˆê¸° ë¡œë“œ: ì„¸ì…˜ì— ì €ì¥
if "faiss_index" not in st.session_state or "faiss_meta" not in st.session_state:
    index, metadata = load_index_and_metadata()
    st.session_state["faiss_index"] = index
    st.session_state["faiss_meta"] = metadata
    st.session_state["last_refresh"] = time.time()

# â± ê°±ì‹  ë¡œì§
def should_refresh_index():
    return time.time() - st.session_state["last_refresh"] > FAISS_REFRESH_INTERVAL

if should_refresh_index():
    index, metadata = load_index_and_metadata()
    st.session_state["faiss_index"] = index
    st.session_state["faiss_meta"] = metadata
    st.session_state["last_refresh"] = time.time()

# ğŸ–¥ï¸ UI êµ¬ì„±
st.set_page_config(page_title="Ontology RAG QA", page_icon="ğŸ“¦")
st.title("ğŸ“¦ ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ RAG ì§ˆì˜ì‘ë‹µ")

user_input = st.text_input("ğŸ—£ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ë¡±ë¹„ì¹˜í•­ì˜ ìœ„ë„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?")

# ğŸ¤– GPT ì‘ë‹µ
if user_input:
    with st.spinner("ğŸ¤– GPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        answer = generate_answer(
            user_input,
            st.session_state["faiss_index"],
            st.session_state["faiss_meta"]
        )
        st.markdown("### ğŸ¤– GPT ì‘ë‹µ")
        st.success(answer)

        # ğŸ” ìœ ì‚¬ë„ ê²°ê³¼ ë³´ê¸°
        st.markdown("### ğŸ” ìœ ì‚¬ë„ ê¸°ë°˜ ê´€ë ¨ ë¬¸ì¥")
        results = search_faiss(
            get_embedding(user_input),
            st.session_state["faiss_index"],
            st.session_state["faiss_meta"],
            k=5
        )
        for i, (text, score) in enumerate(results, 1):
            st.markdown(f"**{i}. ({score:.4f})** {text}")

# ğŸ“Š ë²¡í„° ìƒíƒœ ì •ë³´ (Sidebar)
with st.sidebar:
    st.header("ğŸ“Š FAISS ìƒíƒœ")
    index = st.session_state["faiss_index"]
    metadata = st.session_state["faiss_meta"]
    st.markdown(f"**ì‚¬ìš© gpt ëª¨ë¸**: `{os.getenv('GPT_MODEL')}`")
    st.sidebar.markdown("---")
    st.markdown(f"**ì´ ë²¡í„° ìˆ˜**: `{index.ntotal}`")
    st.sidebar.markdown("---")
    st.sidebar.markdown("ğŸ” **ì‚¬ìš© ì¤‘ì¸ íŒŒì¼ ê²½ë¡œ**")
    st.sidebar.markdown(f"- **Index**: `{os.getenv('FAISS_INDEX_FILE')}`")
    st.sidebar.markdown(f"- **Metadata**: `{os.getenv('FAISS_META_FILE')}`")
    st.markdown("---")
    st.subheader("ğŸ§¾ ìµœê·¼ ë“±ë¡ ë¬¸ì¥")

    if metadata:
        st.markdown("""
        <div style='height: 300px; overflow-y: auto; padding-right:10px;'>
        """, unsafe_allow_html=True)

        for i, item in enumerate(metadata[::-1][:100]):  # ì „ì²´ í‘œì‹œ
            full_text = item["text"] if isinstance(item, dict) else str(item)
            st.markdown(f"**#{index.ntotal - i}**:<br>{full_text}<hr>", unsafe_allow_html=True)

        st.markdown("</div>", unsafe_allow_html=True)
    else:
        st.markdown("ë“±ë¡ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
