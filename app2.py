import streamlit as st
import time
import os
from dotenv import load_dotenv
from aiqa.rag_query import generate_answer
from embedding.faiss_store import load_index_and_metadata

# ğŸ“¦ .env ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
FAISS_REFRESH_INTERVAL = int(os.getenv("FAISS_REFRESH_INTERVAL", 60))

# ğŸ“ ì´ˆê¸° ë¡œë“œ: ì„¸ì…˜ì— ì €ì¥
if "faiss_index" not in st.session_state or "faiss_meta" not in st.session_state:
    index, metadata = load_index_and_metadata()
    st.session_state["faiss_index"] = index
    st.session_state["faiss_meta"] = metadata
    st.session_state["last_refresh"] = time.time()

# â± ê°±ì‹  ë¡œì§
def should_refresh_index():
    return time.time() - st.session_state["last_refresh"] > FAISS_REFRESH_INTERVAL

if should_refresh_index():
    index, metadata = load_index_and_metadata()
    st.session_state["faiss_index"] = index
    st.session_state["faiss_meta"] = metadata
    st.session_state["last_refresh"] = time.time()

# ğŸ–¥ï¸ UI êµ¬ì„±
st.set_page_config(page_title="Ontology RAG QA", page_icon="ğŸ“¦")
st.title("ğŸ“¦ ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ RAG ì§ˆì˜ì‘ë‹µ")

user_input = st.text_input("ğŸ—£ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", placeholder="ì˜ˆ: ë¡±ë¹„ì¹˜í•­ì˜ ìœ„ë„ëŠ” ì–¼ë§ˆì¸ê°€ìš”?")

# ğŸ¤– GPT ì‘ë‹µ
if user_input:
    with st.spinner("ğŸ¤– GPTê°€ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        answer = generate_answer(
            user_input,
            st.session_state["faiss_index"],
            st.session_state["faiss_meta"]
        )
        st.markdown("### ğŸ¤– GPT ì‘ë‹µ")
        st.success(answer)

# ğŸ“Š ë²¡í„° ìƒíƒœ ì •ë³´ (Sidebar)
with st.sidebar:
    st.header("ğŸ“Š FAISS ìƒíƒœ")
    index = st.session_state["faiss_index"]
    metadata = st.session_state["faiss_meta"]
    st.markdown(f"**ì´ ë²¡í„° ìˆ˜**: `{index.ntotal}`")
    st.markdown("---")
    st.subheader("ğŸ§¾ ìµœê·¼ ë“±ë¡ ë¬¸ì¥")
    if metadata:
        for i, text in enumerate(metadata[-3:][::-1]):
            st.markdown(f"**#{index.ntotal - i}**: {text[:100]}...")
    else:
        st.markdown("ë“±ë¡ëœ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
