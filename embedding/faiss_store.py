# faiss_store.py

import faiss
import numpy as np
import pickle
import os
from typing import List, Tuple

from dotenv import load_dotenv
load_dotenv()

FAISS_INDEX_FILE

VECTOR_SIZE = 1536  # OpenAI embedding vector size (e.g., text-embedding-ada-002)
INDEX_FILE = os.getenv("FAISS_INDEX_FILE")
# "faiss_index.index"
META_FILE = os.getenv("FAISS_META_FILE")
# "faiss_metadata.pkl"

# ë¬¸ì¥ + ë²¡í„°ë¥¼ FAISS ì¸ë±ìŠ¤ì™€ ë©”íƒ€ë°ì´í„°ë¡œ ì €ì¥
def save_embeddings_to_faiss(sentences: List[str], embeddings: List[List[float]]):
    vectors = np.array(embeddings, dtype="float32")
    index = faiss.IndexFlatL2(VECTOR_SIZE)
    index.add(vectors)

    faiss.write_index(index, INDEX_FILE)

    with open(META_FILE, "wb") as f:
        pickle.dump(sentences, f)

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {len(sentences)}ê°œ ë¬¸ì¥ì„ FAISSì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

# FAISSì™€ ë¬¸ì¥ ë©”íƒ€ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
def load_faiss_index() -> Tuple[faiss.IndexFlatL2, List[str]]:
    index = faiss.read_index(INDEX_FILE)
    with open(META_FILE, "rb") as f:
        sentences = pickle.load(f)
    return index, sentences

# ì§ˆì˜ ë²¡í„°ì— ëŒ€í•´ ìœ ì‚¬í•œ ë¬¸ì¥ top-k ê²€ìƒ‰
def search_faiss(query_vector: List[float], k: int = 5) -> List[str]:
    index, sentences = load_faiss_index()
    query = np.array([query_vector], dtype="float32")
    distances, indices = index.search(query, k)
    return [sentences[i] for i in indices[0]]

def append_to_faiss_index(new_sentences: List[str], new_embeddings: List[List[float]]):
    assert len(new_sentences) == len(new_embeddings), "ğŸ›‘ ë¬¸ì¥ê³¼ ì„ë² ë”© ìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    new_vectors = np.array(new_embeddings, dtype="float32")

    if os.path.exists(INDEX_FILE) and os.path.exists(META_FILE):
        # ê¸°ì¡´ ì¸ë±ìŠ¤ ë° ë¬¸ì¥ ë¡œë”©
        index = faiss.read_index(INDEX_FILE)
        with open(META_FILE, "rb") as f:
            sentences = pickle.load(f)
    else:
        # ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
        index = faiss.IndexFlatL2(VECTOR_SIZE)
        sentences = []

    # ìƒˆ ì„ë² ë”© ì¶”ê°€
    index.add(new_vectors)
    sentences.extend(new_sentences)

    # ì €ì¥
    faiss.write_index(index, INDEX_FILE)
    with open(META_FILE, "wb") as f:
        pickle.dump(sentences, f)

    print(f"âœ… FAISS ì¸ë±ìŠ¤ì— {len(new_sentences)}ê°œ ë¬¸ì¥ì„ ì¶”ê°€ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

save_faiss_index = save_embeddings_to_faiss