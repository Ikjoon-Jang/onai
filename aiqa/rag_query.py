from embedding.embedding import get_embedding
from embedding.faiss_store import search_faiss, load_index_and_metadata
from openai import OpenAI
from dotenv import load_dotenv
import os
import numpy as np
import logging

load_dotenv()

# OpenAI ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)
GPT_MODEL = "gpt-3.5-turbo"

# GPT ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_answer(user_question: str, index=None, metadata=None, top_k: int = 10) -> str:
    try:
        # 1. ì‚¬ìš©ì ì§ˆë¬¸ ì„ë² ë”©
        query_vec = get_embedding(user_question)

        # 2. ì¸ë±ìŠ¤/ë©”íƒ€ë°ì´í„° ìë™ ë¡œë”©
        if index is None or metadata is None:
            index, metadata = load_index_and_metadata()

        # 3. FAISS ê²€ìƒ‰
        results = search_faiss(query_vec, index, metadata, k=top_k)

        if not results:
            return "â— ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”."

        # 4. ìœ ì‚¬ë„ í¬í•¨ context êµ¬ì„±
        context_sentences = [f"[{score:.4f}] {text}" for text, score in results]
        context = "\n".join(context_sentences)

        # ğŸ” DEBUG ì¶œë ¥
        print("\nğŸ“Œ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸:")
        for i, (text, score) in enumerate(results, 1):
            print(f"[{i}] ({score:.4f}) {text[:80]}...")

        # 5. GPT ì§ˆì˜
        messages = [
            {
                "role": "system",
                "content": (
                    "You are an expert AI assistant that uses domain knowledge to answer questions based on the provided context. "
                    "Answer accurately and concisely. If the context is insufficient, respond that the information is not available."
                )
            },
            {
                "role": "user",
                "content": f"Context:\n{context}\n\nQuestion: {user_question}",
            },
        ]

        response = client.chat.completions.create(
            model=GPT_MODEL,
            messages=messages,
            temperature=0.3,
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        logging.error(f"âŒ GPT ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
        return f"â— GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
