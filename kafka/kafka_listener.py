# kafka_listener.py
from kafka import KafkaConsumer
import json
import logging
import time
from utils.json_to_individual import json_to_rdf
from fuseki.fuseki_insert import insert_triple_to_fuseki
from update.update_pipeline import update_single_individual_index

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("logs/kafka_listener.log", encoding="utf-8"),
        logging.StreamHandler()
    ],
)

def parse_kv_string_to_dict(message_str: str) -> dict:
    result = {}
    for item in message_str.strip().split():
        if ':' in item:
            key, value = item.split(':', 1)
            result[key.strip()] = value.strip()
    return result

KAFKA_BROKER = '3.36.178.68:9092'  # í•„ìš” ì‹œ ìˆ˜ì •
KAFKA_TOPIC = 'qlinx-orders'       # ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” í† í”½ëª…ìœ¼ë¡œ ë³€ê²½

def start_kafka_listener():
    consumer = KafkaConsumer(
        KAFKA_TOPIC,
        bootstrap_servers=[KAFKA_BROKER],
        auto_offset_reset='latest',
        enable_auto_commit=True,
        group_id=f'onai-test-group-{int(time.time())}',  # â† ìœ ì¼í•œ ê·¸ë£¹ ID
        value_deserializer=lambda m: m.decode('utf-8'),  # â† JSON ì•„ë‹˜
    )

    logging.info(f"ğŸ“¡ Kafka Topic '{KAFKA_TOPIC}' ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...")

    for message in consumer:
        try:
            logging.info("ğŸ”¥ Kafka ë©”ì‹œì§€ ë£¨í”„ ì§„ì… ì„±ê³µ!")
            data = message.value

            if not data.strip():
                logging.warning("âš ï¸ ë¹ˆ ë©”ì‹œì§€ ìˆ˜ì‹ ë¨. ê±´ë„ˆëœ€.")
                continue
            
            if not data:
                logging.warning("âš ï¸ ìˆ˜ì‹ ëœ ë©”ì‹œì§€ ê°’ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                continue

            logging.info(f"ğŸ“¥ ë©”ì‹œì§€ ìˆ˜ì‹ : #####{data}#####")

            rdf_graph = json_to_rdf(data)
            logging.info(f"ğŸ§¾ ë³€í™˜ëœ RDF triple ìˆ˜: {len(rdf_graph)}")
            for s, p, o in rdf_graph:
                logging.info(f"â–¶ï¸ {s} {p} {o}")

            inserted = insert_triple_to_fuseki(rdf_graph)

            if inserted:
                individual_uri = str([s for s, p, o in rdf_graph if str(p).endswith("#type")][0])
                update_single_individual_index(individual_uri)

        except Exception as e:
            logging.error(f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

if __name__ == "__main__":
    start_kafka_listener()
